'use client';

import React, { useState, useRef, useCallback } from 'react';
import Tesseract, { createWorker } from 'tesseract.js';
import { useLanguage } from '../../contexts/LanguageContext';

interface CameraCaptureProps {
  onReadingExtracted: (value: string) => void;
  isProcessing?: boolean;
}

export default function CameraCapture({ onReadingExtracted, isProcessing = false }: CameraCaptureProps) {
  const { t } = useLanguage();
  const [isCapturing, setIsCapturing] = useState(false);
  const [isLoadingCamera, setIsLoadingCamera] = useState(false);
  const [isProcessingOCR, setIsProcessingOCR] = useState(false);
  const [capturedImage, setCapturedImage] = useState<string | null>(null);
  const [isCameraReady, setIsCameraReady] = useState(false);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string>('');
  const [ocrProgress, setOcrProgress] = useState<number>(0);
  
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  // Verificar soporte de c√°mara
  const checkCameraSupport = (): boolean => {
    return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
  };

  // Iniciar c√°mara
  const startCamera = useCallback(async () => {
    try {
      setError('');
      setIsCapturing(false); // Reset estado antes de empezar
      setIsLoadingCamera(true); // Mostrar indicador de carga
      
      // Verificar soporte de c√°mara
      if (!checkCameraSupport()) {
        setError(t('cameraCapture.cameraNotSupported'));
        setIsLoadingCamera(false);
        return;
      }
      
      console.log('Solicitando acceso a la c√°mara...');
      
      // Configuraci√≥n optimizada para m√≥viles
      const isMobile = window.innerWidth <= 768;
      const constraints: MediaStreamConstraints = {
        video: {
          facingMode: 'environment', // Usar c√°mara trasera en m√≥viles
          width: { 
            min: 640,
            ideal: isMobile ? 1024 : 1920, 
            max: isMobile ? 1280 : 1920 
          },
          height: { 
            min: 480,
            ideal: isMobile ? 768 : 1080, 
            max: isMobile ? 960 : 1080 
          },
          aspectRatio: { ideal: 4/3 }, // Mejor para captura de documentos
          frameRate: { ideal: 30, max: 30 }
        }
      };
      
      // Intentar con configuraci√≥n completa primero
      let mediaStream: MediaStream;
      try {
        console.log('Intentando configuraci√≥n completa...');
        mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
      } catch (err) {
        // Si falla, intentar con configuraci√≥n b√°sica
        console.warn('Falling back to basic camera configuration:', err);
        mediaStream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: 'environment'
          }
        });
      }
      
      console.log('C√°mara obtenida exitosamente');
      
      // --- INICIO DE C√ìDIGO DE DIAGN√ìSTICO ---
      console.log('Stream de c√°mara obtenido:', mediaStream);
      console.log('Tracks activos:', mediaStream.getTracks());
      console.log('Referencia del <video>:', videoRef.current);
      // --- FIN DE C√ìDIGO DE DIAGN√ìSTICO ---
      
      setStream(mediaStream);
      setIsCapturing(true);
      setIsLoadingCamera(false); // Ocultar indicador de carga
      
      // Usar setTimeout para asegurar que el DOM se actualice antes de acceder al video
      setTimeout(() => {
        if (videoRef.current) {
          videoRef.current.srcObject = mediaStream;
          
          // Configurar eventos del video
          videoRef.current.onloadedmetadata = () => {
            console.log('Video metadata cargada');
            setTimeout(() => {
              setIsCameraReady(true);
            }, 1000); // Dar tiempo para que la c√°mara se estabilice
          };
          
          // Reproducir video directamente
          console.log('Iniciando reproducci√≥n del video...');
          videoRef.current.play().catch(err => {
            console.error('ERROR AL INTENTAR REPRODUCIR VIDEO:', err);
            setError(t('cameraCapture.cameraError'));
            setIsCapturing(false);
            setIsLoadingCamera(false);
          });
        } else {
          console.error('ERROR CR√çTICO: La referencia al elemento <video> es NULA.');
          setError(t('cameraCapture.cameraError'));
          setIsCapturing(false);
          setIsLoadingCamera(false);
        }
      }, 100); // 100ms delay para permitir que el DOM se actualice
        
      // Timeout de seguridad
      setTimeout(() => {
        if (videoRef.current && videoRef.current.readyState === 0) {
          console.error('Video no se carg√≥ en tiempo esperado');
          setError(t('cameraCapture.cameraError'));
          setIsCapturing(false);
          setIsLoadingCamera(false);
          stopCamera();
        }
      }, 10000); // 10 segundos timeout
    } catch (err: any) {
      console.error('Error accessing camera:', err);
      setIsCapturing(false); // Asegurar que el estado se resetee
      setIsLoadingCamera(false); // Ocultar indicador de carga
      
      // Mensajes de error espec√≠ficos
      if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
        setError(t('cameraCapture.permissionDenied'));
      } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
        setError(t('cameraCapture.noCameraFound'));
      } else if (err.name === 'NotSupportedError') {
        setError(t('cameraCapture.cameraNotSupported'));
      } else if (err.name === 'NotReadableError' || err.name === 'TrackStartError') {
        setError(t('cameraCapture.cameraInUse'));
      } else {
        setError(t('cameraCapture.cameraError'));
      }
    }
  }, [t]);

  // Detener c√°mara
  const stopCamera = useCallback(() => {
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
    }
    setIsCapturing(false);
    setIsCameraReady(false);
    setCapturedImage(null);
  }, [stream]);

  // Optimizar imagen para OCR
  const optimizeImageForOCR = (canvas: HTMLCanvasElement, context: CanvasRenderingContext2D): string => {
    // Calcular dimensiones optimizadas (m√°ximo 1920x1080 para mejor rendimiento)
    const maxWidth = 1920;
    const maxHeight = 1080;
    const currentWidth = canvas.width;
    const currentHeight = canvas.height;
    
    let newWidth = currentWidth;
    let newHeight = currentHeight;
    
    if (currentWidth > maxWidth || currentHeight > maxHeight) {
      const ratio = Math.min(maxWidth / currentWidth, maxHeight / currentHeight);
      newWidth = Math.round(currentWidth * ratio);
      newHeight = Math.round(currentHeight * ratio);
      
      // Crear canvas temporal para redimensionar
      const tempCanvas = document.createElement('canvas');
      const tempContext = tempCanvas.getContext('2d');
      if (!tempContext) return canvas.toDataURL('image/jpeg', 0.8);
      
      tempCanvas.width = newWidth;
      tempCanvas.height = newHeight;
      
      // Redimensionar con suavizado
      tempContext.imageSmoothingEnabled = true;
      tempContext.imageSmoothingQuality = 'high';
      tempContext.drawImage(canvas, 0, 0, newWidth, newHeight);
      
      return tempCanvas.toDataURL('image/jpeg', 0.85);
    }
    
    return canvas.toDataURL('image/jpeg', 0.85);
  };

  // Capturar foto con mejor calidad
  const capturePhoto = useCallback(() => {
    if (!videoRef.current || !canvasRef.current) return;
    
    const video = videoRef.current;
    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    
    if (!context) return;
    
    try {
      // Esperar un momento para que el video se estabilice
      setTimeout(() => {
        // Configurar canvas con las dimensiones del video
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        // Verificar que el video tiene dimensiones v√°lidas
        if (canvas.width === 0 || canvas.height === 0) {
          setError(t('cameraCapture.cameraError'));
          return;
        }
        
        console.log(`Capturando foto: ${canvas.width}x${canvas.height}`);
        
        // Configurar contexto para mejor calidad
        context.imageSmoothingEnabled = true;
        context.imageSmoothingQuality = 'high';
        
        // Dibujar el frame actual del video en el canvas
        context.drawImage(video, 0, 0, canvas.width, canvas.height);
        
        // Aplicar mejoras de contraste y nitidez para OCR
        const imageData = context.getImageData(0, 0, canvas.width, canvas.height);
        const data = imageData.data;
        
        // Mejorar contraste (opcional, puede ayudar con texto poco visible)
        for (let i = 0; i < data.length; i += 4) {
          // Aumentar ligeramente el contraste
          const factor = 1.1;
          data[i] = Math.min(255, data[i] * factor);     // Red
          data[i + 1] = Math.min(255, data[i + 1] * factor); // Green
          data[i + 2] = Math.min(255, data[i + 2] * factor); // Blue
        }
        
        context.putImageData(imageData, 0, 0);
        
        // Optimizar imagen para OCR con mayor calidad
        const imageDataUrl = canvas.toDataURL('image/jpeg', 0.92); // Mayor calidad
        setCapturedImage(imageDataUrl);
        
        // Detener la c√°mara despu√©s de capturar
        stopCamera();
        
        // Procesar la imagen con OCR
        processImageWithOCR(imageDataUrl);
      }, 200); // Peque√±o delay para estabilizar la imagen
    } catch (err) {
      console.error('Error capturing photo:', err);
      setError(t('cameraCapture.cameraError'));
    }
  }, [stopCamera, t]);

  // Validar imagen antes del procesamiento
  const validateImage = (file: File): Promise<boolean> => {
    return new Promise((resolve) => {
      // Verificar tipo de archivo
      if (!file.type.startsWith('image/')) {
        setError(t('cameraCapture.invalidFileType'));
        resolve(false);
        return;
      }
      
      // Verificar tama√±o (m√°ximo 10MB)
      if (file.size > 10 * 1024 * 1024) {
        setError(t('cameraCapture.fileTooLarge'));
        resolve(false);
        return;
      }
      
      // Verificar que la imagen se puede cargar
      const img = new Image();
      img.onload = () => {
        // Verificar dimensiones m√≠nimas
        if (img.width < 100 || img.height < 100) {
          setError(t('cameraCapture.imageTooSmall'));
          resolve(false);
        } else {
          resolve(true);
        }
      };
      img.onerror = () => {
        setError(t('cameraCapture.invalidImage'));
        resolve(false);
      };
      img.src = URL.createObjectURL(file);
    });
  };

  // Manejar selecci√≥n de archivo
  const handleFileSelect = useCallback(async (event: React.ChangeEvent<HTMLInputElement>) => {
    const file = event.target.files?.[0];
    if (!file) return;
    
    setError('');
    
    // Validar imagen
    const isValid = await validateImage(file);
    if (!isValid) return;
    
    const reader = new FileReader();
    reader.onload = (e) => {
      const imageDataUrl = e.target?.result as string;
      setCapturedImage(imageDataUrl);
      processImageWithOCR(imageDataUrl);
    };
    reader.onerror = () => {
      setError(t('cameraCapture.fileReadError'));
    };
    reader.readAsDataURL(file);
  }, []);

  // Validar imagen antes del OCR
  const validateImageForOCR = (imageDataUrl: string): Promise<boolean> => {
    return new Promise((resolve) => {
      const img = new Image();
      img.onload = () => {
        // Verificar que la imagen tiene dimensiones v√°lidas
        if (img.width < 50 || img.height < 50) {
          setError(t('cameraCapture.imageTooSmall'));
          resolve(false);
        } else if (img.width > 4000 || img.height > 4000) {
          setError(t('cameraCapture.imageTooLarge'));
          resolve(false);
        } else {
          resolve(true);
        }
      };
      img.onerror = () => {
        setError(t('cameraCapture.invalidImage'));
        resolve(false);
      };
      img.src = imageDataUrl;
    });
  };

  // Procesar imagen con OCR
  const processImageWithOCR = useCallback(async (imageDataUrl: string) => {
    setIsProcessingOCR(true);
    setError('');
    setOcrProgress(0);
    
    try {
      // Validar imagen antes del procesamiento
      const isValidForOCR = await validateImageForOCR(imageDataUrl);
      if (!isValidForOCR) {
        return;
      }

      // Crear worker con configuraci√≥n mejorada
      const worker = await createWorker('spa', 1, {
        logger: m => {
          if (m.status === 'recognizing text') {
            setOcrProgress(Math.round(m.progress * 100));
          }
        },
        errorHandler: (err) => {
          console.error('Tesseract Worker Error:', err);
        }
      });
      
      try {
        // Configurar Tesseract para mejorar la detecci√≥n de n√∫meros
        await worker.setParameters({
          tessedit_char_whitelist: '0123456789.,', // Solo n√∫meros, puntos y comas
          tessedit_pageseg_mode: Tesseract.PSM.SINGLE_BLOCK, // Uniform block of text
          preserve_interword_spaces: '0',
          tessedit_ocr_engine_mode: '1' // Neural nets LSTM engine
        });
        
        // Procesar imagen
        const { data: { text, confidence } } = await worker.recognize(imageDataUrl);
        
        // Verificar confianza del OCR
        if (confidence < 30) {
          setError(t('cameraCapture.lowConfidence'));
          return;
        }
        
        // Extraer n√∫meros del texto reconocido
        const extractedNumbers = extractMeterReading(text);
        
        if (extractedNumbers) {
          onReadingExtracted(extractedNumbers);
        } else {
          setError(t('cameraCapture.noReadingDetected'));
        }
      } finally {
        // Asegurar que el worker se termine siempre
        await worker.terminate();
      }
    } catch (err: any) {
      console.error('OCR Error:', err);
      
      // Mensajes de error m√°s espec√≠ficos
      if (err.message?.includes('network') || err.message?.includes('fetch')) {
        setError(t('cameraCapture.networkError'));
      } else if (err.message?.includes('memory') || err.message?.includes('allocation')) {
        setError(t('cameraCapture.memoryError'));
      } else if (err.message?.includes('read image')) {
        setError(t('cameraCapture.imageReadError'));
      } else {
        setError(t('cameraCapture.ocrError'));
      }
    } finally {
      setIsProcessingOCR(false);
      setOcrProgress(0);
    }
  }, [onReadingExtracted]);

  // Extraer lectura del medidor del texto OCR
  const extractMeterReading = (text: string): string | null => {
    // Limpiar el texto
    const cleanText = text.replace(/\s+/g, ' ').trim();
    
    // Buscar patrones de n√∫meros que podr√≠an ser lecturas de medidor
    // Patrones comunes: 12345, 12345.6, 12,345.6, etc.
    const patterns = [
      /\b(\d{3,6}(?:[.,]\d{1,2})?)\b/g, // 3-6 d√≠gitos con decimales opcionales
      /\b(\d{4,})\b/g, // 4 o m√°s d√≠gitos consecutivos
    ];
    
    const foundNumbers: string[] = [];
    
    patterns.forEach(pattern => {
      const matches = cleanText.match(pattern);
      if (matches) {
        foundNumbers.push(...matches);
      }
    });
    
    if (foundNumbers.length === 0) return null;
    
    // Tomar el n√∫mero m√°s largo (probablemente la lectura principal)
    const longestNumber = foundNumbers.reduce((longest, current) => 
      current.replace(/[.,]/g, '').length > longest.replace(/[.,]/g, '').length ? current : longest
    );
    
    // Normalizar el formato (usar punto como decimal)
    return longestNumber.replace(',', '.');
  };

  return (
    <div className="bg-gradient-to-br from-green-50 to-emerald-100 border-2 border-green-200 rounded-2xl shadow-xl p-6 mb-6">
      <div className="flex items-center justify-center mb-4">
        <div className="bg-gradient-to-r from-green-600 to-emerald-600 text-white p-3 rounded-full shadow-lg mr-3">
          <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M3 9a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 0110.07 4h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0018.07 7H19a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9z" />
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M15 13a3 3 0 11-6 0 3 3 0 016 0z" />
          </svg>
        </div>
        <div>
          <h3 className="text-lg font-bold text-gray-800">{t('cameraCapture.title')}</h3>
          <p className="text-gray-600 text-sm">{t('cameraCapture.description')}</p>
        </div>
      </div>

      {error && (
        <div className="bg-red-50 border-2 border-red-200 rounded-xl p-3 mb-4">
          <div className="flex items-center">
            <svg className="w-5 h-5 text-red-500 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 8v4m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
            </svg>
            <p className="text-red-700 text-sm">{error}</p>
          </div>
        </div>
      )}

      {isProcessingOCR && (
        <div className="bg-blue-50 border-2 border-blue-200 rounded-xl p-4 mb-4">
          <div className="flex items-center mb-2">
            <svg className="animate-spin w-5 h-5 text-blue-600 mr-2" fill="none" viewBox="0 0 24 24">
              <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
              <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            <span className="text-blue-700 font-medium">{t('cameraCapture.processing')} {ocrProgress}%</span>
          </div>
          <div className="w-full bg-blue-200 rounded-full h-2">
            <div 
              className="bg-blue-600 h-2 rounded-full transition-all duration-300" 
              style={{ width: `${ocrProgress}%` }}
            ></div>
          </div>
        </div>
      )}

      {/* Video preview para c√°mara */}
      {isCapturing && (
        <div className="mb-4">
          <video 
            ref={videoRef} 
            autoPlay 
            playsInline 
            muted
            className="w-full max-w-lg mx-auto rounded-xl border-2 border-gray-300 h-auto aspect-[4/3] object-cover"
            style={{ maxHeight: '400px' }}
          />
          
          {/* Indicador de estado de la c√°mara */}
          <div className="flex justify-center mt-3 mb-2">
            {!isCameraReady ? (
              <div className="flex items-center bg-orange-100 text-orange-700 px-4 py-2 rounded-full text-sm font-medium">
                <svg className="animate-pulse w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
                  <circle cx="10" cy="10" r="3"/>
                </svg>
                üì∑ Enfocando c√°mara...
              </div>
            ) : (
              <div className="flex items-center bg-green-100 text-green-700 px-4 py-2 rounded-full text-sm font-medium">
                <svg className="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
                  <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd"/>
                </svg>
                ‚úÖ C√°mara lista para capturar
              </div>
            )}
          </div>
          
          <div className="flex justify-center gap-4 mt-2">
            <button
              onClick={capturePhoto}
              disabled={!isCameraReady}
              className={`px-8 py-4 rounded-2xl font-bold text-lg transition-all duration-200 shadow-lg min-w-[120px] touch-manipulation ${
                isCameraReady 
                  ? 'bg-green-600 hover:bg-green-700 active:bg-green-800 text-white hover:shadow-xl transform hover:scale-105 active:scale-95' 
                  : 'bg-gray-400 text-gray-200 cursor-not-allowed'
              }`}
            >
              üì∏ {isCameraReady ? t('cameraCapture.capture') : 'Esperando...'}
            </button>
            <button
              onClick={stopCamera}
              className="bg-gray-600 hover:bg-gray-700 active:bg-gray-800 text-white px-8 py-4 rounded-2xl font-bold text-lg transition-all duration-200 shadow-lg hover:shadow-xl transform hover:scale-105 active:scale-95 min-w-[120px] touch-manipulation"
            >
              ‚ùå {t('cameraCapture.cancel')}
            </button>
          </div>
        </div>
      )}

      {/* Imagen capturada */}
      {capturedImage && (
        <div className="mb-4">
          <img 
            src={capturedImage} 
            alt={t('cameraCapture.capturedImage')} 
            className="w-full max-w-md mx-auto rounded-xl border-2 border-gray-300"
          />
          <div className="flex justify-center mt-3">
            <button
              onClick={() => {
                setCapturedImage(null);
                setError('');
              }}
              className="bg-gray-600 hover:bg-gray-700 text-white px-4 py-2 rounded-xl text-sm transition-colors"
            >
              {t('cameraCapture.delete')}
            </button>
          </div>
        </div>
      )}

      {/* Indicador de carga de c√°mara */}
      {isLoadingCamera && (
        <div className="bg-blue-50 border-2 border-blue-200 rounded-xl p-4 mb-4">
          <div className="flex items-center justify-center">
            <svg className="animate-spin w-6 h-6 text-blue-600 mr-3" fill="none" viewBox="0 0 24 24">
              <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
              <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            <span className="text-blue-700 font-medium">Iniciando c√°mara...</span>
          </div>
        </div>
      )}

      {/* Botones de acci√≥n */}
      {!isCapturing && !capturedImage && !isLoadingCamera && (
        <div className="grid grid-cols-1 md:grid-cols-2 gap-3">
          <button
            onClick={startCamera}
            disabled={isProcessing || isProcessingOCR || isLoadingCamera}
            className="flex items-center justify-center bg-gradient-to-r from-green-600 to-emerald-600 hover:from-green-700 hover:to-emerald-700 text-white px-4 py-3 rounded-xl font-medium transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed"
          >
            <svg className="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M3 9a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 0110.07 4h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0018.07 7H19a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9z" />
            </svg>
            {t('cameraCapture.openCamera')}
          </button>
          
          <button
            onClick={() => fileInputRef.current?.click()}
            disabled={isProcessing || isProcessingOCR || isLoadingCamera}
            className="flex items-center justify-center bg-gradient-to-r from-blue-600 to-indigo-600 hover:from-blue-700 hover:to-indigo-700 text-white px-4 py-3 rounded-xl font-medium transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed"
          >
            <svg className="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z" />
            </svg>
            {t('cameraCapture.selectImage')}
          </button>
        </div>
      )}

      {/* Input oculto para seleccionar archivos */}
      <input
        ref={fileInputRef}
        type="file"
        accept="image/*"
        onChange={handleFileSelect}
        className="hidden"
      />

      {/* Canvas oculto para captura */}
      <canvas ref={canvasRef} className="hidden" />

      {/* Instrucciones */}
      <div className="mt-4 bg-yellow-50 border-2 border-yellow-200 rounded-xl p-3">
        <div className="flex items-start">
          <svg className="w-5 h-5 text-yellow-600 mr-2 mt-0.5 flex-shrink-0" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
          </svg>
          <div>
            <p className="text-yellow-800 font-medium text-sm mb-1">{t('cameraCapture.tipsTitle')}</p>
            <ul className="text-yellow-700 text-xs space-y-1">
              <li>üì± <strong>M√≥viles:</strong> Mant√©n el tel√©fono estable y espera que la imagen se enfoque</li>
              <li>üí° Aseg√∫rate de tener buena iluminaci√≥n, evita sombras sobre el medidor</li>
              <li>üìè Acerca el medidor para que los n√∫meros sean claramente visibles</li>
              <li>üéØ Centra los n√∫meros del medidor en la pantalla antes de capturar</li>
              <li>‚è±Ô∏è Espera 1-2 segundos despu√©s de enfocar antes de tomar la foto</li>
              <li>üîÑ Si la foto sale borrosa, intenta de nuevo con mejor iluminaci√≥n</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  );
}